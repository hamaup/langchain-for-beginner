ようこそ、LCEL 応用編へ！ステップ 5 では、部品を `|` で繋ぐ LCEL の基本を体験しました。便利でしたね！

実際のアプリ開発では、AI の答えをプログラムで使いやすい形にしたり、少し複雑な処理の流れを作ったりすることがよくあります。また、作ったチェーンが期待通りに動かない時に、その原因を探る「デバッグ」も大切なスキルです。

このステップ 6 では、AI から決まった形式のデータ（**構造化データ**）を受け取るチェーンの作り方を学びます。さらに、チェーンの動きを**確認・デバッグする**ための、とても役に立つ具体的な方法を 2 つマスターしましょう。このステップが終われば、LCEL を使ってもっと色々なことができるようになりますよ！

## 1. はじめに：このステップで目指すこと

### 🎯 今回のゴール

このステップを最後まで終えると、あなたはこんなことができるようになります！

- AI の応答を Python の辞書（`dict`）のような**構造化データ**として受け取れる LCEL チェーンを組めるようになります。
- チェーンを作るときに便利なテクニック、特に**元の入力データを途中で使ったり**、**複数の処理結果を一つにまとめたり**する方法（`RunnablePassthrough` の活用）がわかります。
- チェーン実行中に、裏側で何が起きているかを**自動でコンソールに詳しく表示**させる方法 (`ConsoleCallbackHandler`) がわかります。
- チェーンの中の、**「ここが見たい！」という特定の場所**でデータの中身を**手軽に確認**する方法 (`RunnableLambda`) がわかります。
- **具体的な成果物:** サンプルの会議議事録から、目的・決定事項・アクションを抽出して Python 辞書として返す LCEL チェーンと、上で挙げた 2 つのデバッグ方法を試す Python プログラムを作成します。

### 🔑 このステップのポイント

このステップで学ぶ、特に大切な言葉や考え方です。

- **構造化出力:** AI に、プログラムで扱いやすい「形が決まったデータ」（今回は辞書）で答えてもらうこと。
- **`RunnablePassthrough`:** LCEL の部品の一つ。受け取ったデータをそのまま次の部品に「パス」する役割。データフローを調整するのに使う。
- **デバッグ:** 作ったプログラムが正しく動くかテストしたり、もし問題があればその原因を見つけて直したりすること。
- **`ConsoleCallbackHandler`:** デバッグ用の部品。チェーンの動きをコンソールに自動で報告してくれる。
- **`RunnableLambda`:** デバッグ用の部品。好きな関数をチェーンの途中に挟んで、データを確認したりできる。

### ✅ 前提知識

安心して進めるために、以下のことができるか確認しておきましょう。

- ステップ 5 で学んだ LCEL の基本（`|` で繋ぐ、`.invoke()` で実行する）がわかる。
- ステップ 4 で学んだ `StructuredOutputParser` や `ResponseSchema` が何をするためのものか、なんとなく覚えている。
- Python の辞書 (`dict`) の基本的な使い方（キーで値を取り出すなど）がわかる。
- Python の `lambda` を使った簡単な関数（例: `lambda x: x * 2`）を見たことがある、または抵抗がない。
- ステップ 1 で準備した開発環境（Python, 仮想環境, API キーなど）が使える状態である。

---

## 2. 準備運動：ハンズオンのための基礎知識

### 🎯 目標

これからコードを書く前に、なぜ「構造化データ」や「デバッグ」がアプリ開発で重要なのか、そして今回使う新しい「道具」たちが、そのためにどう役立つのかをイメージできるようになりましょう。

### なぜ「構造化データ」や「デバッグ」が必要？

AI が人間のように自然な文章で答えてくれるのは便利ですが、プログラムにとっては少し扱いにくいことがあります。例えば、AI が「決定事項は〇〇です。そして次回のアクションは △△ です。」と答えた場合、プログラムで「決定事項」と「次回のアクション」を正確に取り出すのは意外と面倒です。もし AI が最初から、

```python
{"決定事項": "〇〇", "次回アクション": "△△"}
```

のような、キーと値が決まった形式（**構造化データ**、ここでは Python の辞書）で答えてくれれば、プログラムは `結果['決定事項']` のように簡単に情報を取り出せますよね。このステップでは、LCEL を使って AI にこのような形式で出力させる方法を学びます。

そして**デバッグ**です。LCEL で部品を `|` で繋いでいくと、全体の流れはシンプルになりますが、それぞれの部品の間でデータがどのように受け渡しされているかは、コードを見ただけでは分かりにくいことがあります。もしチェーンが期待通りに動かなかった場合、「プロンプトはちゃんと作られた？」「LLM は変な答えを返してない？」「パーサーはうまく変換できた？」のように、**途中の状態を確認する**ことが問題解決の鍵になります。このステップでは、そのための具体的な「覗き見」の方法を学びます。

### 今回使う主な「道具」たち

ステップ 5 までに学んだものに加えて、以下の道具（クラスや機能）を使います。これらを組み合わせることで、より高度なチェーンを作ったり、その動きを確認したりできるようになります。

- **`StructuredOutputParser`** (`langchain.output_parsers` より):
  - これは、AI (LLM) の応答を指定したデータ構造（今回は Python の辞書）に変換してくれる「整形職人」です。ステップ 4 で使い方を見ましたね。LCEL チェーンの出口に取り付けることで、プログラムで扱いやすい形のデータを取り出せます。ただし、AI が指示通りの形式で応答しないと、エラーになることもあります。
- **`RunnablePassthrough`** (`langchain_core.runnables` より):
  - これは「素通りさせる」部品です。受け取ったデータを**何も加工せずに、そのまま次の部品に渡します**。これがなぜ便利かというと、例えば「最初にチェーンに入れたデータを、最後のほうでも使いたい」という場合に、この部品を使ってデータを「脇に保持しておく」ような動きを作れるからです。また、複数の処理を組み合わせる際にも役立ちます。
  - <details><summary>どこからインポートする？</summary>LCEL の基本的な部品なので、`langchain_core` というコアパッケージから `from langchain_core.runnables import RunnablePassthrough` としてインポートします。</details>
- **`RunnableLambda`** (`langchain_core.runnables` より):
  - これは、あなたが書いた Python の**関数を LCEL チェーンの部品に変身させる**魔法です。特に `lambda` を使った短い関数と組み合わせることが多いです。これの主な使い道はデバッグで、チェーンの途中に `print()` 文を挟んで、「今、どんなデータが流れてる？」と**コンソールに表示させる**ことができます。
  - <details><summary>どこからインポートする？</summary>これも基本部品なので `langchain_core` から `from langchain_core.runnables import RunnableLambda` でインポートします。</details>
  - **【超重要】** `RunnableLambda` で使う関数は、受け取ったデータを**必ず `return` で返す**必要があります。もし `return` を忘れると、データが次の部品に渡らず、チェーンがそこで止まってしまいます！
- **パイプ `|` と辞書 `{}` の組み合わせ**:
  - LCEL では `前のRunnable | {"キーA": RunnableA, "キーB": RunnableB}` のように書くことで、面白いことができます。
  - `前のRunnable` から出力されたデータが、`RunnableA` と `RunnableB` の**両方**に渡されて、**並行して**処理されます。
  - それぞれの処理結果が `"キーA"` と `"キーB"` の値として、**一つの新しい辞書**にまとめられて出力されます。これは、複数の情報を同時に取得・加工したい場合にとても便利です。
- **`ConsoleCallbackHandler`** (`langchain.callbacks.tracers` より):
  - これは、チェーンの実行中に舞台裏で何が起きているかを**自動でコンソールに実況中継**してくれる「解説者」のような部品です。
  - これを有効にすると、「チェーン開始！」「LLM 呼び出し開始！」「LLM 応答受信！」「チェーン終了！」といったイベントとその時のデータ（一部）がコンソールに表示され、処理の流れを追いやすくなります。
- **`config={'callbacks': [ハンドラーのリスト]}`**:
  - `.invoke()` などでチェーンを実行する際に、この `config` 引数を渡すことで、`ConsoleCallbackHandler` のような「解説者」を有効にできます。
  - `callbacks` の値が `[]`（リスト）になっているのは、複数の種類の「解説者」（コールバックハンドラー）を同時に任命できるからです。今回は `ConsoleCallbackHandler` を一つだけ指定します。

---

## 3. 実践タイム：コードを書いて動かしてみよう！

### 🎯 目標

さあ、実際にコードを書いて、以下のことをやってみましょう！

1.  AI の応答を Python 辞書として受け取る LCEL チェーンを作る。
2.  `RunnablePassthrough` と辞書 `{}` を使って、元の入力と AI の回答をセットで出力する。
3.  `ConsoleCallbackHandler` を使って、チェーン実行時の詳細ログを出力させる。
4.  `RunnableLambda` を使って、チェーンの途中（プロンプト生成直後）のデータを出力させる。

### ファイルの準備

- 作業フォルダ（例: `langchain-project`）の中に `step6_lcel_debugging_intro.py` という名前で新しい Python ファイルを作成（または編集）してください。

### 実践 1: `StructuredOutputParser` を使ったチェーン構築

まずは基本の確認。ステップ 4 で扱った「会議議事録の要約」を LCEL で組みます。AI から辞書形式で結果を受け取ることを目指します。

```python
# step6_lcel_debugging_intro.py (実践1部分)
import os
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
# 構造化出力に必要な部品
from langchain.output_parsers import ResponseSchema, StructuredOutputParser
# LCELのコア部品 (PassthroughとLambda)
from langchain_core.runnables import RunnablePassthrough, RunnableLambda
# プロンプトやメッセージの型情報 (型ヒントや中身確認用)
from langchain_core.prompt_values import ChatPromptValue
from langchain_core.messages import AIMessage
# 文字列パーサー (後で使う)
from langchain_core.output_parsers import StrOutputParser
# デバッグ用コールバックハンドラー
from langchain.callbacks.tracers import ConsoleCallbackHandler

# --- 初期設定 ---
# .envファイルからAPIキーなどを読み込む
load_dotenv()
print("--- 環境変数読み込み完了 ---")

# LLM (ChatGPT) を準備する
try:
    # temperature=0 で、毎回同じような応答を期待する
    llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0)
    print(f"--- LLM準備完了: {llm.model_name} (temperature={llm.temperature}) ---")
    print("   (temperature=0 は応答の多様性を抑え、結果を安定させるための設定です)")
except Exception as e:
    print(f"❌ エラー: ChatOpenAI の初期化に失敗しました: {e}")
    print("   (APIキーが正しく設定されているか確認してください)")
    exit() # 続行不可

# --- 実践 1: StructuredOutputParser を使ったチェーン ---
print("\n--- 実践 1: StructuredOutputParser を使ったチェーン ---")

# サンプルの議事録
meeting_minutes_text = """
# 会議議事録 (2025/04/07)
参加者: 山田, 佐藤, 田中
決定事項:
- 新機能AのUI調整は田中が担当 (〆切: 今週末)
- プロモーション計画案は佐藤が修正 (〆切: 水曜)
次回アクション:
- 鈴木がテスト準備 (来週月曜開始)
"""

# 1. どんな情報を、どんな名前で抽出したいか定義 (ResponseSchema)
print("   1. 出力形式の設計図(Schema)を定義中...")
purpose_schema = ResponseSchema(name="purpose", description="会議の主な目的や議題 (string)")
decisions_schema = ResponseSchema(name="decisions", description="決定事項のリスト (list[str])")
actions_schema = ResponseSchema(name="next_actions", description="次回アクションのリスト (list[str])")
response_schemas = [purpose_schema, decisions_schema, actions_schema]

# 2. 設計図をもとに、AI応答を辞書に変換するパーサーを作成
print("   2. 構造化パーサー(StructuredOutputParser)を作成中...")
output_parser_structured = StructuredOutputParser.from_response_schemas(response_schemas)
# パーサーから、LLMに渡すための「出力形式の指示」を取り出す
format_instructions = output_parser_structured.get_format_instructions()
print("   StructuredOutputParser準備完了")


# 3. プロンプトテンプレートを作成 (入力: minutes, format_instructions)
print("   3. プロンプトテンプレートを作成中...")
prompt_template_structured = ChatPromptTemplate.from_template(
    """以下の会議議事録を分析し、指定された形式で情報を抽出してください。

議事録:
{minutes}

出力形式の指示:
{format_instructions}"""
)
print("   プロンプトテンプレート準備完了")

# 4. LCEL チェーンを構築！ (プロンプト -> LLM -> 構造化パーサー)
print("   4. LCEL チェーンを構築中...")
chain_structured = prompt_template_structured | llm | output_parser_structured
print("   チェーン構築完了 (プロンプト | LLM | StructuredOutputParser)")

# 5. チェーンを実行して結果を確認
try:
    # プロンプトに必要な入力データを辞書で渡す
    input_data_structured = {
        "minutes": meeting_minutes_text,
        "format_instructions": format_instructions
    }
    print(f"\n   実行中... 入力キー: {input_data_structured.keys()}")

    # チェーン実行！ output_parser_structured が最後なので辞書が返るはず
    output_dict = chain_structured.invoke(input_data_structured)
    print("✅ OK: 応答を受信しました。")

    # 結果の確認
    print("\n   【応答の型】:", type(output_dict)) # -> <class 'dict'>
    print("   【応答 (辞書)】:")
    print("   ", output_dict)
    # 辞書の中身も確認
    print("\n   抽出された決定事項:", output_dict.get('decisions')) # -> list

except Exception as e:
    print(f"❌ エラー: チェーン (Structured) の実行中にエラーが発生しました: {e}")
    print("   ヒント: LLMが指示通りの形式で出力しなかった場合、ここでパースエラーが起こることがあります。")

```

- **何を確認するか:** 最後の出力が Python の辞書 (`dict`) になり、`decisions` のようなキーで中身（リスト）を取り出せることを確認しましょう。

### 実践 2: `RunnablePassthrough` と辞書で入力と出力を組み合わせる

今度は、簡単な質問応答で、「元の質問」と「AI の回答」を両方含む辞書を作るチェーンに挑戦します。ここで `RunnablePassthrough` と辞書 `{}` の組み合わせテクニックを使います。

```python
# step6_lcel_debugging_intro.py (実践2部分)
print("\n--- 実践 2: RunnablePassthrough と辞書で入力と出力を組み合わせる ---")

# 質問応答用のプロンプトと、シンプルな文字列パーサー
prompt_qa = ChatPromptTemplate.from_template("{question} について簡潔に教えてください。")
parser_str = StrOutputParser()

# チェーンを定義する
print("   チェーン構築中...")
chain_combined = (
    # 1. まず RunnablePassthrough を置き、入力辞書 {"question": ...} をそのまま次に渡す
    RunnablePassthrough()
    # 2. 次のステップは辞書。前のステップからの入力が、この辞書内の各キーの処理に渡される
    | {
        # 3. 'question' キーの処理:
        #    渡された入力辞書から 'question' の値を取り出す関数(lambda)を指定
        #    -> これで元の質問が保持される
        "question": lambda input_dict: input_dict["question"],

        # 4. 'answer' キーの処理:
        #    渡された入力辞書をそのまま回答生成チェーンに渡す
        #    (prompt_qaが入力辞書から'question'を使い、LLMが回答し、parser_strが文字列にする)
        "answer": prompt_qa | llm | parser_str
      }
)
# 結果として、{"question": 元の質問, "answer": AIの回答} という辞書が出力される
print("   チェーン構築完了 (RunnablePassthrough | 辞書を使用)")

try:
    # 最初の入力データ（質問）
    input_qa = {"question": "大規模言語モデル"}
    print(f"\n   実行中... 入力: {input_qa}")

    # チェーンを実行
    result_dict = chain_combined.invoke(input_qa)
    print("✅ OK: 応答を受信しました。")

    # 結果を確認
    print("\n   【応答の型】:", type(result_dict)) # -> <class 'dict'>
    print("   【応答 (辞書)】:")
    print("   ", result_dict)
    # 辞書の中身を確認
    print("\n   元の質問:", result_dict.get("question"))
    print("   AIの回答:", result_dict.get("answer"))

except Exception as e:
    print(f"❌ エラー: チェーン (Combined) の実行中にエラーが発生しました: {e}")
```

- **何を確認するか:** 最終的な出力が、`'question'` と `'answer'` という 2 つのキーを持つ辞書になっていることを確認しましょう。`RunnablePassthrough` と辞書 `{}` によって、入力と処理結果がうまく結合されています。

### 実践 3: `ConsoleCallbackHandler` で実行過程を追跡する

デバッグの時間です！実践 2 で作った `chain_combined` を実行するときに、`ConsoleCallbackHandler` を使って内部の動きをログ出力させてみましょう。

```python
# step6_lcel_debugging_intro.py (実践3部分)
print("\n--- 実践 3: ConsoleCallbackHandler で実行過程を追跡する ---")
print("   ▼ chain_combined を ConsoleCallbackHandler 付きで実行:")

try:
    # 別の質問で試してみる
    input_qa_callback = {"question": "Reactフレームワーク"}
    print(f"\n   実行中... 入力: {input_qa_callback}")

    # 1. ConsoleCallbackHandler のインスタンス（実物）を用意する
    console_callback = ConsoleCallbackHandler()

    # 2. invoke() メソッドの config 引数に、'callbacks' キーで指定する
    #    値はリスト形式で、中に用意したインスタンスを入れる
    #    (複数の Callback Handler を同時に使うことも可能)
    result_callback = chain_combined.invoke(
        input_qa_callback,
        config={'callbacks': [console_callback]} # Callback 有効化！
    )

    # --- ここに注目！ ---
    # 上記 invoke() の実行中に、コンソールに [chain/start], [llm/start]
    # などの色付きのログが自動で出力されるはずです。
    # 処理の開始・終了や入出力データがわかります。
    # --------------------

    print("\n✅ OK: Callback Handler 付きでの実行が完了しました。(ログは上記に出力されているはずです)")
    # 最終的な結果自体は result_callback に入っている (今回はログ確認が目的なので表示は省略)
    # print("\n   最終結果:", result_callback)

except Exception as e:
    print(f"❌ エラー: チェーン (Callback) の実行中にエラーが発生しました: {e}")

```

- **何を確認するか:** スクリプトを実行した際、この「実践 3」の部分で、`[chain/start]` や `[llm/end]` などで始まる**色付きのログ**がコンソールにたくさん表示されることを確認しましょう。これが Callback Handler によるデバッグ出力です。

### 実践 4: `RunnableLambda` で特定の中間データを出力する

もう一つのデバッグ方法、`RunnableLambda` です。チェーンの**特定の箇所**を流れるデータの中身を、自分で書いた関数（ここでは `print` するだけ）を使って覗き見してみましょう。今回は、プロンプトテンプレート (`prompt_qa`) が LLM に渡す**直前のデータ**を出力させてみます。

```python
# step6_lcel_debugging_intro.py (実践4部分)
print("\n--- 実践 4: RunnableLambda で特定の中間データを出力する ---")

# デバッグ用の関数を定義:
#   - 引数名 (ここでは prompt_value) は、何を受け取るか分かりやすい名前にする
#   - 中身を表示 (print) する
#   - ★★★ 必ず受け取った引数をそのまま return する ★★★
def print_prompt_info(prompt_value: ChatPromptValue):
    """プロンプト生成後の ChatPromptValue を受け取り、コンソールに表示してからそのまま返す関数"""
    print("\n---- [RunnableLambda が受け取ったプロンプト情報 START] ----")
    print(f"型: {type(prompt_value)}") # 型を表示
    print("内容:")
    # 中のメッセージリストを分かりやすく表示
    for message in prompt_value.to_messages():
        print(f"- {type(message).__name__}: {message.content}")
    print("---- [RunnableLambda が受け取ったプロンプト情報 END] ----")

    # 重要！ 次のステップにデータを渡すために、必ず return する
    return prompt_value

# チェーンの定義: プロンプトとLLMの間に RunnableLambda を挿入！
print("   チェーン構築中...")
chain_with_lambda = (
    prompt_qa                          # 1. 入力からプロンプト情報を生成
    | RunnableLambda(print_prompt_info) # 2. ★生成されたプロンプト情報をここで表示★
    | llm                              # 3. プロンプト情報をLLMに渡す
    | parser_str                       # 4. LLMの応答(AIMessage)を文字列に
)
print("   チェーン構築完了 (RunnableLambda を使用)")

try:
    # 別の質問で試す
    input_qa_lambda = {"question": "Pythonのジェネレータ"}
    print(f"\n   実行中... 入力: {input_qa_lambda}")

    # チェーンを実行！ 途中で print_prompt_info が呼び出されるはず
    result_lambda = chain_with_lambda.invoke(input_qa_lambda)
    print("\n✅ OK: Lambda 付きチェーンの実行が完了しました。")
    print("   最終結果:", result_lambda)

except Exception as e:
    print(f"❌ エラー: チェーン (Lambda) の実行中にエラーが発生しました: {e}")

print("\n--- 全ての処理が終了しました ---")
```

- **何を確認するか:** 実行中に `---- [RunnableLambda が受け取ったプロンプト情報 START] ----` で囲まれたブロックが表示され、そこに `ChatPromptValue` の型と、LLM に渡される直前のメッセージ（`HumanMessage: ...`）の内容が表示されていることを確認しましょう。

### 完成コード (`step6_lcel_debugging_intro.py`)

上記の実践 1〜4 のコードをすべて結合し、必要な import 文を冒頭にまとめたものが最終的なコードとなります。

---

## 4. 深掘り解説：仕組みをもっと詳しく知ろう

### 🎯 目標

- `ConsoleCallbackHandler` と `RunnableLambda` を使ったデバッグ手法のそれぞれの利点と、どのような場面で使い分けるかを理解する。

### デバッグ手法 `ConsoleCallbackHandler` vs `RunnableLambda`

今回学んだ 2 つのデバッグ方法は、状況に応じて使い分けるのが賢いやり方です。

- **`ConsoleCallbackHandler`（自動報告係）:**
  - **良い点:**
    - チェーンのコードを変えずに、`config` で指定するだけで使える。
    - チェーン全体の主要な動き（どの部品がいつ呼ばれ、何を受け取り、何を出したか）を自動で記録してくれる。全体像の把握に向いている。
  - **注意点:**
    - 出力される情報や形式は決まっている。特定のデータだけを細かく見たい時には情報過多かも。
    - ログ出力の分だけ、わずかに処理時間が増える可能性がある（通常は問題にならない程度）。
  - **いつ使う？:** まずチェーン全体の動きをざっくり確認したい時。どこかでエラーが起きているが、場所が特定できない時。
- **`RunnableLambda`（手動チェックポイント）:**
  - **良い点:**
    - チェーンの中の**好きな場所**に、**好きな処理**（`print` で特定の変数だけ表示するなど）を挟める。
    - 「ここを流れるデータだけ見たい！」という場合にピンポイントで確認できる。
  - **注意点:**
    - チェーンの定義自体にデバッグ用のコードが混ざってしまう。
    - 関数内で**必ず `return` を書かないと、そこでデータの流れが止まってしまう**。
  - **いつ使う？:** 特定の部品の出力内容だけを確認したい時。一時的にサッとデータを確認したい時。

**使い分けのヒント:**
まずは `ConsoleCallbackHandler` で全体の流れを見て、問題がありそうな箇所やもっと詳しく見たいデータがあれば、`RunnableLambda` で狙いを定めて確認する、という合わせ技が効果的です。

(注: 実際の開発では、これらの方法に加えて、Python の `logging` モジュールを使ってログをファイルに保存したり、LangSmith のような専用ツールを使ったりすることも一般的です。)

---

## 5. 最終チェック：動作確認と問題解決

### 🎯 目標

- `ConsoleCallbackHandler` と `RunnableLambda` を使ったデバッグが、自分の環境で正しく動作することを確認する。

### 確認してみよう

- **実行方法:** コマンドラインで `step6_lcel_debugging_intro.py` を実行します。
- **確認パターン:**
  - 最後までエラーが出ずに完了しましたか？
  - 実践 1 の出力は Python の辞書 (`dict`) でしたか？
  - 実践 2 の出力は `'question'` と `'answer'` を持つ辞書でしたか？
  - **実践 3 の実行中に、`[chain/start]` などで始まる色付きのログが表示されましたか？**
  - **実践 4 の実行中に、`---- [RunnableLambda が受け取ったプロンプト情報 START] ----` で始まるブロックが表示されましたか？**
  - 試しに、実践 2 や 3, 4 の `input_qa` の質問内容を変えて実行してみて、応答やログが変わることも確認してみましょう。

---

## 6. まとめ：学びの整理と次へのステップ

### 🎯 目標

- このステップで学んだ、LCEL チェーンの応用的な構築方法と、実践的なデバッグ手法をしっかり自分のものにする。

### ✅ 達成したこと！

お疲れ様でした！このステップで以下のことができるようになりました。

- `StructuredOutputParser` を LCEL チェーンで使い、AI から構造化データ（辞書）を受け取れた。
- `RunnablePassthrough` と辞書 `{}` を組み合わせて、元の入力と処理結果を一つの辞書にまとめるテクニックを学んだ。
- `ConsoleCallbackHandler` を使って、チェーンの実行中の詳細な動きをコンソールログで確認できた。
- `RunnableLambda` を使って、チェーンの好きな場所のデータの中身を `print` 文などで確認できた（そして `return` の重要性も！）。

### 🔑 学んだキーワード

- LCEL, Runnable, `|`
- `StructuredOutputParser`
- `RunnablePassthrough`, `RunnableLambda` (`langchain_core` から)
- 辞書リテラルによる並列実行パターン
- `ConsoleCallbackHandler` (デバッグ用コールバック)
- チェーンのデバッグ

### 🚀 次のステップへ！

LCEL チェーンを自在に組み上げ、その内部をデバッグする方法も身につきましたね。これで、より複雑な処理にも挑戦できる準備が整いました！

さて、これまでの `.invoke()` では、AI が応答をすべて考え終わるまで、じっと待っている必要がありました。チャットアプリなどでは、相手のメッセージが少しずつ表示されるほうが自然ですよね。

次の **ステップ 7「応答がスムーズに！逐次表示を試そう」** では、`Runnable` が持つ `.stream()` というメソッドを使います。これを使うと、AI の応答をまるでタイピングしているかのように、**少しずつリアルタイムに受け取る**ことができるようになります（これを**ストリーミング**と呼びます）。ユーザー体験を向上させる重要なテクニックです。お楽しみに！
