前のステップでは、長い文章を扱いやすいサイズに分割する方法を学びました。しかし、分割されたテキストチャンクも、コンピュータにとってはまだ単なる文字の並びです。コンピュータがテキストの「意味」を理解し、例えば「似た内容のチャンクを探す」といった高度な処理を行うためには、もう一手間必要になります。

このステップでは、テキストをコンピュータが理解しやすい**数値のリスト (ベクトル)** に変換する魔法のような技術、**Embedding (エンベディング)** について学びます。これにより、テキストデータが意味のある数値表現に変わり、様々な AI アプリケーションの基盤となります。

## 1. はじめに：このステップで目指すこと

### 🎯 今回のゴール

このステップを終えると、以下のことができるようになります。

- テキストを数値ベクトルに変換する **`Embedding`** の基本的な概念とその重要性を理解します。
- LangChain を使って、テキストデータを **`Embedding` モデル** (今回は OpenAI のモデルを使用) を通じてベクトルに変換する方法を習得します。
- **具体的な成果物:** 簡単なテキスト文字列や、テキストのリスト (前のステップで分割したチャンクを想定) を、OpenAI の Embedding モデルを使って数値ベクトルのリストに変換する Python コードを作成します。

### 🔑 このステップのポイント

このステップで特に重要な考え方や技術です。

- **`Embedding` (埋め込み)**: テキストなどの情報を、その意味的な特徴を捉えた**数値ベクトル**に変換する技術またはその結果のベクトル自体を指します。
- **`OpenAIEmbeddings`**: OpenAI が提供する高性能な Embedding モデルを LangChain から利用するためのクラスです。API キーが必要となり、利用には料金が発生します。

### ✅ 前提知識

このステップをスムーズに進めるために、以下の知識があると役立ちます。

- Python の基本的な文法（リスト操作、環境変数の扱いなど）。
- ステップ 13「長文を分割！テキスト分割の技法」で学んだ、テキストをチャンクに分割する考え方。（必須ではありませんが、Embedding の主な利用場面として関連します）
- ステップ 1 で取得・設定した **OpenAI API キー**。Embedding モデルの利用にも必要です。

---

## 2. 準備運動：ハンズオンのための基礎知識

### 🎯 目標

テキストを数値ベクトルに変換する **`Embedding`** とは何か、そしてなぜそれが AI アプリケーションで重要なのか、基本的な考え方を理解しましょう。

### `Embedding` (埋め込み) とは？ - 言葉を数字の地図へ

コンピュータは「こんにちは」や「さようなら」といった言葉そのものを直接理解することは苦手です。コンピュータが得意なのは数値計算です。そこで、言葉や文章の意味を捉えた**数値のリスト (ベクトル)** に変換する技術が考え出されました。これが **`Embedding`** です。

例えば、「猫」と「犬」はどちらもペットであり、「机」や「椅子」よりも互いに意味が近いですよね。Embedding モデルは、このような言葉の意味的な関係性を学習し、「猫」を表すベクトルと「犬」を表すベクトルが、ベクトル空間（数字で作られた地図のようなもの）の中で比較的近い位置に来るように、そして「机」のベクトルとは遠い位置に来るように、言葉を数字のリストに変換します。

### なぜベクトル表現が便利なのか？

テキストをベクトルに変換すると、以下のようなメリットがあります。

- **意味の近さを計算できる**: ベクトル同士の距離や角度を計算することで、元のテキスト同士がどれくらい意味的に似ているかを数値で評価できます。
- **検索**: 大量の文書の中から、質問文と意味的に最も近い文書（ベクトルが近い文書）を効率的に探し出すことができます。(これは RAG システムの根幹技術です)
- **分類**: テキストがどのカテゴリに属するかを、ベクトルの特徴から判断できます。
- **その他**: クラスタリング、推薦システムなど、多くの AI 技術の基礎として利用されています。

### LangChain における Embedding モデル

LangChain は、様々な Embedding モデルを統一的なインターフェースで利用できるようにしています。

今回は、非常に高性能で広く使われている **`OpenAIEmbeddings`** を使います。

### 今回使う道具

- **`OpenAIEmbeddings`**:
  - OpenAI の Embedding API を呼び出し、テキストをベクトルに変換するためのクラスです。
  - **インポート元とインストール**: このクラスは **`langchain-openai`** パッケージに含まれています。利用するには、まずパッケージをインストールする必要があります。
    ```bash
    pip install -U langchain-openai
    ```
    そして、Python コード内で以下のようにインポートします。
    ```python
    from langchain_openai import OpenAIEmbeddings
    ```
  - **API キー**: このクラスを使うには、**OpenAI API キー**が必要です。後述する方法で設定します。
  - **利用料金**: OpenAI Embedding API の利用は**有料**です。利用したテキストの量（トークン数）に応じて料金が発生します。OpenAI の料金ページで最新情報を確認してください。
- **`.embed_query(text: str)` メソッド**:
  - **単一のテキスト文字列** をベクトル化します。主に検索クエリなどに使います。
- **`.embed_documents(texts: List[str])` メソッド**:
  - **複数のテキスト文字列を含むリスト** をまとめてベクトル化します。文書チャンクなどに使います。

---

## 3. 実践タイム：テキストをベクトルに変換してみよう！

### 🎯 目標

実際に Python コードを書き、`OpenAIEmbeddings` を使って単一および複数のテキストをベクトルに変換し、その結果を確認します。

### ステップ・バイ・ステップ実装

#### 1. 必要なモジュールのインポートと準備:

`OpenAIEmbeddings` クラスと、API キーを環境変数から読み込むための `os` モジュール、そして `.env` ファイルを使う場合に備えて `dotenv` をインポートします。

```python
# step14_embedding_intro_revised.py
import os
import sys
from dotenv import load_dotenv # .env ファイルを使う場合に必要

# OpenAIEmbeddings をインポート
try:
    from langchain_openai import OpenAIEmbeddings
    print("OpenAIEmbeddings をインポートしました (from langchain_openai)。")
except ImportError:
    print("エラー: langchain-openai が見つかりません。")
    print("   'pip install -U langchain-openai' を実行してください。")
    sys.exit(1)

print("--- 必要なモジュールのインポート完了 ---")

# --- APIキーの準備 ---
# 方法1: 環境変数から直接読み込む (推奨)
openai_api_key = os.getenv("OPENAI_API_KEY")

# 方法2: .env ファイルから読み込む (環境変数が設定されていない場合)
if not openai_api_key:
    print("環境変数 OPENAI_API_KEY が未設定です。 .env ファイルからの読み込みを試みます。")
    if load_dotenv():
        openai_api_key = os.getenv("OPENAI_API_KEY")
        if openai_api_key:
            print(".env ファイルから API キーを読み込みました。")
        else:
            print("警告: .env ファイルに OPENAI_API_KEY が見つかりませんでした。")
    else:
        print("警告: .env ファイルが見つかりませんでした。")

# APIキーが最終的に設定されているか確認
if not openai_api_key:
    print("エラー: OpenAI API キーが設定されていません。")
    print("環境変数 または .env ファイルに OPENAI_API_KEY を設定してください。")
    sys.exit(1)
else:
    # セキュリティのため、キーの一部のみ表示 (オプション)
    print(f"OpenAI API キーが読み込まれました (キーの先頭: {openai_api_key[:5]}...)")

```

- API キーは、環境変数 `OPENAI_API_KEY` に直接設定するか、作業フォルダの `.env` ファイルに `OPENAI_API_KEY='your_key_here'` と記述しておくことで読み込めます。環境変数からの直接読み込みがより推奨されます。

#### 2. `OpenAIEmbeddings` の初期化 (モデルと次元数を指定):

`OpenAIEmbeddings` クラスのインスタンスを作成します。ここでは、公式ドキュメントで推奨されているように、**モデル名を明示的に指定**し、必要であれば**次元数も指定**します。

```python
# step14_embedding_intro_revised.py (続き)

try:
    # モデル名と、オプションで次元数を指定して初期化
    # text-embedding-3-small が一般的だが、large も利用可能 (高性能/高コスト)
    # dimensions を指定しない場合、モデルのデフォルト次元数 (例: 1536) になる
    embeddings_model = OpenAIEmbeddings(
        model="text-embedding-3-small", # モデル名を明示的に指定
        # dimensions=512, # 必要なら次元数を削減 (オプション)
        api_key=openai_api_key # 環境変数から読み込んだキーを渡す
    )
    print(f"\n--- OpenAIEmbeddings 初期化完了 ---")
    print(f"  使用モデル: {embeddings_model.model}")
    # dimensions を指定した場合、それが反映されるか確認 (指定しなければ None)
    print(f"  指定次元数: {embeddings_model.dimensions}")

except Exception as e:
    # APIキーが無効、ネットワークエラー、不正なモデル名などでエラーが発生する可能性
    print(f"エラー: OpenAIEmbeddings の初期化に失敗しました: {e}")
    print("   考えられる原因: APIキーが無効、モデル名が間違っている、ネットワーク接続など。")
    sys.exit(1)
```

- `model`: 使用する OpenAI のモデル名を指定します (例: `"text-embedding-3-small"`, `"text-embedding-3-large"`)。
- `dimensions`: (オプション) 出力ベクトルの次元数を指定できます。モデルが対応していれば、デフォルトよりも小さい次元数 (例: 512, 1024) を指定でき、ストレージ効率や検索速度を改善できる場合があります。
- `api_key`: 読み込んだ API キーを渡します。

#### 3. 単一テキストのベクトル化 (`.embed_query()`):

```python
# step14_embedding_intro_revised.py (続き)
print("\n--- 単一テキストのベクトル化 (.embed_query) ---")

query_text = "こんにちは、世界！"
print(f"入力テキスト: '{query_text}'")

try:
    query_vector = embeddings_model.embed_query(query_text)
    print("ベクトル化完了。")

    print(f"  ベクトル型: {type(query_vector)}")
    print(f"  ベクトル次元数: {len(query_vector)}") # 指定した dimensions またはデフォルト次元数
    print(f"  ベクトルの一部 (最初の5要素): {query_vector[:5]}...")

except Exception as e:
    # API呼び出し時のエラー (レート制限、接続エラーなど)
    print(f"エラー: embed_query の実行中にエラーが発生しました: {e}")
    print("   考えられる原因: APIキーの問題、ネットワーク接続、OpenAI API側の問題 (レート制限など)。")

```

- 返されるベクトルの次元数は、`OpenAIEmbeddings` 初期化時に `dimensions` で指定した値、またはモデルのデフォルト値になります。

#### 4. 複数テキストの一括ベクトル化 (`.embed_documents()`):

```python
# step14_embedding_intro_revised.py (続き)
print("\n--- 複数テキストの一括ベクトル化 (.embed_documents) ---")

document_texts = [
    "LangChain は LLM アプリケーション開発を支援します。",
    "テキストをベクトルに変換するのが Embedding です。",
    "ベクトル検索は RAG の重要な要素です。"
]
print(f"入力テキストリスト (計 {len(document_texts)} 件):")
for i, text in enumerate(document_texts):
    print(f"  {i+1}. '{text}'")

try:
    document_vectors = embeddings_model.embed_documents(document_texts)
    print("一括ベクトル化完了。")

    print(f"  結果の型: {type(document_vectors)}")
    print(f"  ベクトル数: {len(document_vectors)}")
    if document_vectors:
        print(f"  各ベクトルの次元数: {len(document_vectors[0])}")
        print(f"  最初のテキストのベクトル (最初の5要素): {document_vectors[0][:5]}...")
        print(f"  2番目のテキストのベクトル (最初の5要素): {document_vectors[1][:5]}...")
    else:
        print("  ベクトルリストが空です。")

except Exception as e:
    print(f"エラー: embed_documents の実行中にエラーが発生しました: {e}")
    print("   考えられる原因: APIキーの問題、ネットワーク接続、OpenAI API側の問題 (レート制限など)。")


print("\n--- 処理終了 ---")
```

- ここでも、各ベクトルの次元数は、初期化時に指定した値（またはデフォルト値）になります。

### 完成コード (`step14_embedding_intro_revised.py`)

上記の実装 1〜4 を結合したものが完成コードとなります。

---

## 4. 深掘り解説：Embedding の仕組みと活用

### 🎯 目標

Embedding がどのようにテキストの意味を捉えているのか、その概念をもう少し理解し、モデル選択やコストに関する注意点を学びます。

### Embedding の仕組み（概念）

Embedding モデルは、大量のテキストデータから「単語や文がどのような文脈で使われるか」を学習します。その結果、意味的に近い単語や文が、多次元の数値空間（ベクトル空間）の中で近い位置に来るように、テキストをベクトルに変換します。`.embed_query()` や `.embed_documents()` は、入力テキストをこの学習済みモデルに通し、対応するベクトルを計算して返します。

### ベクトルの次元数と削減

ベクトルの次元数は、使用するモデルや設定によって決まります。

- `text-embedding-3-small`: デフォルト 1536 次元
- `text-embedding-3-large`: デフォルト 3072 次元

`OpenAIEmbeddings` では、`dimensions` パラメータを使って、モデルが対応する範囲で次元数を**削減**することが可能です (例: `dimensions=512`)。次元数を減らすと、ベクトルデータの保存に必要なストレージ容量が減り、ベクトル検索の速度が向上する可能性がありますが、表現できる情報の精度がわずかに低下する可能性もあります。用途に応じてトレードオフを考慮して設定します。

### Embedding モデルの選択肢

- **OpenAI**:
  - `text-embedding-3-small`: バランスの取れた性能とコスト。
  - `text-embedding-3-large`: より高性能だが高コスト。
- **Hugging Face**: `HuggingFaceEmbeddings` などを使えば、多くのオープンソースモデル（日本語特化モデルなど）を利用できます。API コストはかかりませんが、自分でモデルを動かす環境や、性能・速度の調整が必要になる場合があります。
- **その他**: Cohere, Google Vertex AI など、様々なプラットフォームが Embedding モデルを提供しており、LangChain はそれらに対応するクラスを用意しています。

### Embedding のコストとオプション

- **API 利用料金**: `OpenAIEmbeddings` は OpenAI API を呼び出すため、処理したテキスト量（トークン数）に応じた**料金が発生**します。大量の文書を処理する場合は特にコストを意識しましょう。
- **キャッシュ**: `OpenAIEmbeddings(..., cache=True)` のように `cache` オプションを有効にすると、同じテキストに対する Embedding 結果をメモリにキャッシュし、重複した API コールとコストを削減できます（開発中に便利ですが、プログラム再起動でキャッシュは消えます）。
- **正規化**: `OpenAIEmbeddings(..., normalize=True)` とすると、出力されるベクトルが正規化（長さが 1 になるように調整）されます。これにより、後でコサイン類似度を計算する際に、計算が少し単純になるという利点があります。
- **大量データ処理**: `embed_documents()` は内部である程度のバッチ処理を行いますが、数百万件など非常に大量のテキストを処理する場合、API のレート制限やタイムアウトを避けるために、自分でリストを小さなバッチに分割してループ処理することを検討する場合があります。
- **言語特性**: モデルによっては、得意な言語とそうでない言語があります。日本語のテキストを扱う場合は、日本語データで学習されたモデルや、多言語対応が明記されているモデルを選ぶと、より良い結果が得られる可能性があります。

---

## 5. 最終チェック：ベクトル化は成功した？

### 🎯 目標

作成したコードが正しく動作し、テキストが期待通りにベクトル表現に変換されていることを確認します。

### 確認してみよう！

- **実行**: `step14_embedding_intro_revised.py` を実行してください。（事前に `pip install -U langchain-openai python-dotenv` と API キーの設定が必要です）
- **エラー**: API キー関連のエラー (例: `AuthenticationError`) やネットワークエラーが出ずに最後まで実行できましたか？ 改善されたエラーハンドリングで、もしエラーが出た場合に原因が推測しやすいメッセージが表示されましたか？
- **`.embed_query()` の結果**:
  - `query_vector` は Python の `list` 型ですか？
  - 次元数は `OpenAIEmbeddings` 初期化時に指定した `dimensions` (指定した場合) またはモデルのデフォルト次元数になっていますか？
  - リストの中身は数値ですか？
- **`.embed_documents()` の結果**:
  - `document_vectors` はリスト (`list`) 型ですか？
  - リストの要素数は入力テキスト数（3）と同じですか？
  - 各ベクトルの次元数は `embed_query` の結果と同じですか？

これらの点が確認できれば、テキストをベクトルに変換する基本操作は成功です！

---

## 6. まとめ：学びの整理と次へのステップ

### ✅ 達成したこと！

これで、テキストデータをコンピュータが意味的に扱える数値ベクトルに変換する Embedding の基本をマスターしました！

- **`Embedding`** の概念と、テキストの意味をベクトルで表現する重要性を理解しました。
- LangChain の **`OpenAIEmbeddings`** クラスを使って、OpenAI のモデルでテキストをベクトル化する方法を学びました（モデル名や次元数の指定方法を含む）。
- 単一テキスト用の **`.embed_query()`** と複数テキスト用の **`.embed_documents()`** の使い方を習得しました。
- API キーの設定方法や利用コスト、キャッシュや正規化などのオプションについても知りました。

### 🔑 学んだキーワード

- **`Embedding` (埋め込み)**
- **ベクトル (Vector)**
- **`OpenAIEmbeddings`** (`langchain_openai` より)
- **`model`**, **`dimensions`** (初期化パラメータ)
- **.embed_query()**
- **.embed_documents()**
- **次元数 (Dimensions)**
- **API キー (API Key)**
- **利用コスト (Cost)**
- **キャッシュ (`cache=True`)**, **正規化 (`normalize=True`)** (オプション)

### 🚀 次のステップへ！

テキストを意味のあるベクトルに変換できるようになりました。これは大きな進歩です！

では、このベクトルデータをどのように活用すればよいのでしょうか？ 特に、大量の文書をベクトル化した場合、その中から特定の質問に関連するベクトル（つまり、関連する文書の一部）を効率的に見つけ出す必要があります。

次の **ステップ 15「情報の検索基盤！Vector Store 基礎」** では、これらのベクトルデータを効率的に保存し、高速に**類似ベクトル検索**を行うためのデータベース、**Vector Store** について学びます。ベクトルデータを検索可能にすることで、RAG (Retrieval-Augmented Generation) システム構築への道が開かれます！
