AI との会話がもっと自然になるためには、「前の話を覚えている」という能力が欠かせません。ステップ 9 では、会話の履歴を記録しておくための基本的な「箱」として `ChatMessageHistory` を学びました。これで会話データをプログラムで管理する基礎はできましたが、毎回手動で履歴を読み書きするのは少し手間がかかります。

このステップでは、LCEL（LangChain Expression Language）で作ったチェーンに、この「記憶力」を自動的に組み込む方法を学びましょう。LangChain には、そのための便利な仕組みが用意されており、これを使うことで、過去の会話の流れを汲んだ応答ができる、より賢いチェーンを簡単に作れるようになります。

## 1. はじめに：このステップで目指すこと

### 🎯 今回のゴール

- LCEL で構築したチェーンに、会話履歴（メモリ）を自動的に組み込む方法を習得します。
- **`RunnableWithMessageHistory`** というクラスを使って、過去の会話履歴を考慮した応答を生成するチェーンを作成できるようになります。
- **具体的な成果物:** ユーザーからの入力を受け取り、過去の会話履歴（`ChatMessageHistory`を使用）を参照して文脈に沿った応答を返す、簡単なチャットボット風の LCEL チェーンを作成します。異なる会話（セッション）ごとに履歴が独立して管理される様子も確認します。

### 🔑 このステップのポイント

- **`RunnableWithMessageHistory`:** 既存の LCEL チェーンに「記憶」機能を追加するための重要なクラスの役割と使い方を理解します。
- **セッション管理:** なぜ会話ごとに履歴を区別する必要があるのかを理解し、そのための「セッション ID」と、ID に基づいて履歴を取得する `get_session_history` 関数の重要性を学びます。
- **プロンプトへの履歴組み込み:** `ChatPromptTemplate` 内で過去の会話履歴を動的に扱うための `MessagesPlaceholder` の使い方をマスターします。

### ✅ 前提知識

- ステップ 9 で学んだ `ChatMessageHistory` の基本的な使い方。
- ステップ 5 と 6 で学んだ LCEL チェーンの構築方法（`|` 演算子、`.invoke()`など）。
- ステップ 3 で学んだ `ChatPromptTemplate` とメッセージ（`SystemMessage`, `HumanMessage`, `AIMessage`）の使い方。
- Python の辞書操作、関数の定義と呼び出し。

---

## 2. 準備運動：ハンズオンのための基礎知識

### 🎯 目標

- なぜ通常の LCEL チェーンにメモリ機能を追加する必要があるのか、そして `RunnableWithMessageHistory` がどのようにその問題を解決するのか、基本的な仕組みを理解します。

### なぜ自動で記憶させたいのか？

これまでの LCEL チェーンは、実行のたびに新しい入力に基づいて応答するだけでした。会話の文脈を保つためには、毎回、過去の履歴を `ChatMessageHistory` から読み出し、プロンプトに加えてからチェーンを実行し、さらに新しいやり取りを履歴に保存する、という手順が必要です。これを手作業で行うのは、コードが複雑になり、間違いも起こりやすくなります。

### `RunnableWithMessageHistory` による自動化

`RunnableWithMessageHistory` は、この問題を解決してくれるクラスです。これは、あなたが作った LCEL チェーン（`Runnable`）をラップし、**チェーンの実行前後に自動的に**会話履歴の**読み込み**と**保存**を行ってくれます。

具体的には、チェーンが呼び出されると、まず指定された方法で現在の会話に対応する履歴を取得し、プロンプトに挿入します。その後、元のチェーンを実行し、最後に今回のユーザー入力と AI の応答を履歴に保存してから、AI の応答を返します。

これにより、チェーン本体のロジック（プロンプト、LLM、パーサー）と、履歴管理のロジックをきれいに分離でき、コードがシンプルになります。

### `RunnableWithMessageHistory` を使うための準備

このクラスを使うには、主に以下のものを準備します。

- **① ラップする対象の `Runnable`:** 実際に処理を行う LCEL チェーン（例: `prompt | llm | parser`）。
- **② `get_session_history` 関数:** **「セッション ID」**（会話を区別するための文字列）を受け取り、その ID に対応する**`ChatMessageHistory` オブジェクト**（または類似のインターフェースを持つオブジェクト）を返す関数を**自分で定義**します。この関数が、どの会話の履歴を使うかを決定します。
- **③ `input_messages_key`:** チェーンに入力する辞書の中で、**ユーザーの現在のメッセージ**が入っているキーの名前を指定します（例: `"input"`）。
- **④ `history_messages_key`:** プロンプトテンプレートの中で、**過去の会話履歴を挿入する場所**を示すプレースホルダ（`MessagesPlaceholder`）の `variable_name` を指定します（例: `"history"`）。

### プロンプトテンプレートと `MessagesPlaceholder`

過去の履歴をプロンプトに組み込むためには、`ChatPromptTemplate` の中で **`MessagesPlaceholder`** を使います。これは「ここには後でメッセージのリストが入りますよ」という場所を示す特別な部品で、`langchain_core.prompts` からインポートします。

```python
# langchain_core.prompts からインポート
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder

prompt = ChatPromptTemplate.from_messages([
    ("system", "あなたは親切なアシスタントです。"),
    # history という名前の変数に履歴メッセージリストが入ることを示す
    MessagesPlaceholder(variable_name="history"),
    ("human", "{input}") # input という名前の変数に現在のユーザー入力が入る
])
```

このようにテンプレートを準備し、`RunnableWithMessageHistory` の `history_messages_key` に `variable_name` と同じ `"history"` を指定すれば、自動的に履歴が挿入されます。

---

## 3. 実践タイム：コードを書いて動かしてみよう！

### 🎯 目標

- `RunnableWithMessageHistory` クラスを使って、会話履歴を自動管理する LCEL チェーンを実際に構築し、実行します。
- セッション ID を使い分けることで、異なる会話の履歴が独立して管理されることを確認します。
- AI への質問は、一般的な知識で答えられるものを使用し、メモリ機能の動作に集中します。

### ステップ・バイ・ステップ実装

#### 1. 必要なモジュールのインポート:

基本的な LCEL コンポーネントと、メモリ関連のモジュールをインポートします。

```python
# step10_lcel_with_memory.py
import os
import sys
from dotenv import load_dotenv

# 基本的な LCEL コンポーネント
from langchain_openai import ChatOpenAI
# MessagesPlaceholder を langchain_core からインポート
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.output_parsers import StrOutputParser

# メモリ関連コンポーネント
# ChatMessageHistory は langchain_community から
try:
    from langchain_community.chat_message_histories import ChatMessageHistory
    print("ChatMessageHistory をインポートしました。")
except ImportError:
    print("エラー: langchain-community がインストールされていません。")
    print("`pip install langchain-community` を実行してください。")
    sys.exit(1)
# BaseChatMessageHistory は型ヒントのため (必須ではない)
from langchain_core.chat_history import BaseChatMessageHistory
# RunnableWithMessageHistory を直接インポート
from langchain_core.runnables.history import RunnableWithMessageHistory

print("--- 必要なモジュールのインポート完了 ---")

# APIキーなどをロード
load_dotenv()

# LLM の準備
try:
    llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0.7)
    print("--- LLM準備完了 ---")
except Exception as e:
    print(f"エラー: LLMの初期化に失敗しました: {e}")
    sys.exit(1)
```

#### 2. 基本的な LCEL チェーンの定義:

履歴が挿入される場所 (`MessagesPlaceholder`) を含んだプロンプトテンプレートと、それを使った基本的なチェーンを定義します。

```python
# step10_lcel_with_memory.py (続き)

# プロンプトテンプレートの定義
prompt = ChatPromptTemplate.from_messages([
    ("system", "あなたはユーザーの質問に簡潔かつ親切に答えるアシスタントです。"),
    MessagesPlaceholder(variable_name="history"), # 履歴用のプレースホルダ
    ("human", "{input}") # ユーザーの現在の入力
])
print("--- プロンプトテンプレート定義完了 ---")

# 出力パーサーの準備
output_parser = StrOutputParser()
print("--- 出力パーサー準備完了 ---")

# メモリ機能を含まない基本チェーン
chain_base = prompt | llm | output_parser
print("--- 基本チェーン定義完了 (prompt | llm | output_parser) ---")
```

#### 3. 履歴管理機能の準備 (`get_session_history`):

セッション ID ごとに `ChatMessageHistory` を管理するための辞書と、`get_session_history` 関数を定義します。今回はインメモリで履歴を保持します。

```python
# step10_lcel_with_memory.py (続き)

# セッションID と ChatMessageHistory オブジェクトのマッピングを保持する辞書
# 注意: この store はインメモリであり、プログラムを再起動すると内容は失われます。
store = {}

# 型ヒントには BaseChatMessageHistory を使うのがより一般的
def get_session_history(session_id: str) -> BaseChatMessageHistory:
    """
    セッションIDに対応する BaseChatMessageHistory オブジェクトを取得または新規作成する関数。
    """
    if session_id not in store:
        print(f"  (新規セッション開始: {session_id})")
        store[session_id] = ChatMessageHistory() # 新しい履歴オブジェクトを作成
    else:
        print(f"  (既存セッション再開: {session_id})")
    return store[session_id] # 対応する履歴オブジェクトを返す

print("--- 履歴管理関数 (get_session_history) 定義完了 ---")
print(f"初期の履歴ストア: {store}")
```

#### 4. `RunnableWithMessageHistory` でメモリ機能付きチェーンを作成:

ステップ 2 で作った `chain_base` とステップ 3 の `get_session_history` 関数などを引数として、`RunnableWithMessageHistory` クラスのインスタンスを作成します。

```python
# step10_lcel_with_memory.py (続き)

# RunnableWithMessageHistory クラスを直接使ってインスタンス化する
chain_with_memory = RunnableWithMessageHistory(
    runnable=chain_base,             # ラップする基本チェーンを指定
    get_session_history=get_session_history, # 上で定義した履歴管理関数
    input_messages_key="input",     # プロンプト内のユーザー入力変数名
    history_messages_key="history"  # プロンプト内の履歴プレースホルダ名
)
print("--- メモリ機能付きチェーン作成完了 (RunnableWithMessageHistoryを使用) ---")

# (補足) LangChainには .with_message_history() という便利なメソッドもありますが、
# バージョンによっては動作しない場合があるため、今回はクラスを直接使う方法を採用しています。
```

#### 5. メモリ付きチェーンの実行と確認 (一般的な質問を使用):

`chain_with_memory.invoke()` を使ってチェーンを実行します。`config` 引数でセッション ID を指定し、AI への質問は一般的なものにします。

```python
# step10_lcel_with_memory.py (続き)

# --- セッションAでの対話 ---
session_a_id = "user_alice" # セッションIDを定義
print(f"\n--- セッション '{session_a_id}' での対話開始 ---")

# 1回目の入力 (セッションA)
print("\n[アリス] 1回目の入力:")
# config 引数でセッションIDを指定
# {"configurable": {"session_id": "..."}} という形式が標準
config_a = {"configurable": {"session_id": session_a_id}}
response_a1 = chain_with_memory.invoke(
    {"input": "こんにちは、私の名前はアリスです。"},
    config=config_a
)
print(f"AI: {response_a1}")

# 2回目の入力 (セッションA - 履歴が使われるはず)
print("\n[アリス] 2回目の入力:")
response_a2 = chain_with_memory.invoke(
    {"input": "私の名前、覚えていますか？"},
    config=config_a # 同じセッションIDを使用
)
print(f"AI: {response_a2}") # -> "アリス" の名前を覚えているはず

# --- セッションBでの対話 ---
session_b_id = "user_bob" # 別のセッションID
print(f"\n--- セッション '{session_b_id}' での対話開始 ---")

# 1回目の入力 (セッションB - セッションAとは独立、一般的な質問)
print("\n[ボブ] 1回目の入力:")
config_b = {"configurable": {"session_id": session_b_id}}
response_b1 = chain_with_memory.invoke(
    # ★ 一般的な質問に変更 ★
    {"input": "日本の首都はどこですか？"},
    config=config_b
)
print(f"AI: {response_b1}")

# --- 再度セッションAでの対話 ---
print(f"\n--- セッション '{session_a_id}' に戻って対話 ---")

# 3回目の入力 (セッションA - 履歴が使われるはず、一般的な質問)
print("\n[アリス] 3回目の入力:")
response_a3 = chain_with_memory.invoke(
    # ★ 一般的な質問に変更 ★
    {"input": "面白いジョークを一つ教えてください。"},
    config=config_a # 再びセッションAのIDを使用
)
print(f"AI: {response_a3}")

# --- 履歴ストアの中身を確認 ---
print("\n--- 最終的な履歴ストアの中身 ---")
# store 辞書の中身をループして、各セッションの履歴を表示
for session_id, history_obj in store.items():
    print(f"セッションID: {session_id}")
    # history_obj は ChatMessageHistory なので .messages で中身が見れる
    for msg in history_obj.messages:
        print(f"  - {type(msg).__name__}: {msg.content}")

print("\n--- 処理終了 ---")
```

### 完成コード (`step10_lcel_with_memory.py`)

```python
# step10_lcel_with_memory.py
import os
import sys
from dotenv import load_dotenv

# 基本的な LCEL コンポーネント
from langchain_openai import ChatOpenAI
# MessagesPlaceholder を langchain_core からインポート
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.output_parsers import StrOutputParser

# メモリ関連コンポーネント
# ChatMessageHistory は langchain_community から
try:
    from langchain_community.chat_message_histories import ChatMessageHistory
    print("ChatMessageHistory をインポートしました。")
except ImportError:
    print("エラー: langchain-community がインストールされていません。")
    print("`pip install langchain-community` を実行してください。")
    sys.exit(1)
# BaseChatMessageHistory は型ヒントのため (必須ではない)
from langchain_core.chat_history import BaseChatMessageHistory
# RunnableWithMessageHistory を直接インポート
from langchain_core.runnables.history import RunnableWithMessageHistory

print("--- 必要なモジュールのインポート完了 ---")

# APIキーなどをロード
load_dotenv()

# LLM の準備
try:
    llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0.7)
    print("--- LLM準備完了 ---")
except Exception as e:
    print(f"エラー: LLMの初期化に失敗しました: {e}")
    sys.exit(1)

# プロンプトテンプレートの定義
prompt = ChatPromptTemplate.from_messages([
    ("system", "あなたはユーザーの質問に簡潔かつ親切に答えるアシスタントです。"),
    MessagesPlaceholder(variable_name="history"), # 履歴用のプレースホルダ
    ("human", "{input}") # ユーザーの現在の入力
])
print("--- プロンプトテンプレート定義完了 ---")

# 出力パーサーの準備
output_parser = StrOutputParser()
print("--- 出力パーサー準備完了 ---")

# メモリ機能を含まない基本チェーン
chain_base = prompt | llm | output_parser
print("--- 基本チェーン定義完了 (prompt | llm | output_parser) ---")


# --- 履歴管理機能の準備 ---
# セッションID と ChatMessageHistory オブジェクトのマッピングを保持する辞書
# 注意: この store はインメモリであり、プログラムを再起動すると内容は失われます。
store = {}

# 型ヒントには BaseChatMessageHistory を使うのがより一般的
def get_session_history(session_id: str) -> BaseChatMessageHistory:
    """
    セッションIDに対応する BaseChatMessageHistory オブジェクトを取得または新規作成する関数。
    """
    if session_id not in store:
        print(f"  (新規セッション開始: {session_id})")
        store[session_id] = ChatMessageHistory()
    else:
        print(f"  (既存セッション再開: {session_id})")
    return store[session_id]

print("--- 履歴管理関数 (get_session_history) 定義完了 ---")
print(f"初期の履歴ストア: {store}")


# --- メモリ機能付きチェーンの作成 ---
# RunnableWithMessageHistory クラスを直接使ってインスタンス化する
chain_with_memory = RunnableWithMessageHistory(
    runnable=chain_base,             # ラップする基本チェーンを指定
    get_session_history=get_session_history, # 上で定義した履歴管理関数
    input_messages_key="input",     # プロンプト内のユーザー入力変数名
    history_messages_key="history"  # プロンプト内の履歴プレースホルダ名
)
print("--- メモリ機能付きチェーン作成完了 (RunnableWithMessageHistoryを使用) ---")

# (補足) LangChainには .with_message_history() という便利なメソッドもありますが、
# バージョンによっては動作しない場合があるため、今回はクラスを直接使う方法を採用しています。


# --- チェーンの実行と確認 (一般的な質問を使用) ---
# --- セッションAでの対話 ---
session_a_id = "user_alice"
print(f"\n--- セッション '{session_a_id}' での対話開始 ---")

print("\n[アリス] 1回目の入力:")
config_a = {"configurable": {"session_id": session_a_id}}
response_a1 = chain_with_memory.invoke(
    {"input": "こんにちは、私の名前はアリスです。"},
    config=config_a
)
print(f"AI: {response_a1}")

print("\n[アリス] 2回目の入力:")
response_a2 = chain_with_memory.invoke(
    {"input": "私の名前、覚えていますか？"},
    config=config_a
)
print(f"AI: {response_a2}")

# --- セッションBでの対話 ---
session_b_id = "user_bob"
print(f"\n--- セッション '{session_b_id}' での対話開始 ---")

print("\n[ボブ] 1回目の入力:")
config_b = {"configurable": {"session_id": session_b_id}}
response_b1 = chain_with_memory.invoke(
    {"input": "日本の首都はどこですか？"}, # 一般的な質問に変更
    config=config_b
)
print(f"AI: {response_b1}")

# --- 再度セッションAでの対話 ---
print(f"\n--- セッション '{session_a_id}' に戻って対話 ---")

print("\n[アリス] 3回目の入力:")
response_a3 = chain_with_memory.invoke(
    {"input": "面白いジョークを一つ教えてください。"}, # 一般的な質問に変更
    config=config_a
)
print(f"AI: {response_a3}")

# --- 履歴ストアの中身を確認 ---
print("\n--- 最終的な履歴ストアの中身 ---")
for session_id, history_obj in store.items():
    print(f"セッションID: {session_id}")
    for msg in history_obj.messages:
        print(f"  - {type(msg).__name__}: {msg.content}")

print("\n--- 処理終了 ---")
```

### 実行結果の例 (一般的な質問版)

```text
ChatMessageHistory をインポートしました。
--- 必要なモジュールのインポート完了 ---
--- LLM準備完了 ---
--- プロンプトテンプレート定義完了 ---
--- 出力パーサー準備完了 ---
--- 基本チェーン定義完了 (prompt | llm | output_parser) ---
--- 履歴管理関数 (get_session_history) 定義完了 ---
初期の履歴ストア: {}
--- メモリ機能付きチェーン作成完了 (RunnableWithMessageHistoryを使用) ---

--- セッション 'user_alice' での対話開始 ---

[アリス] 1回目の入力:
  (新規セッション開始: user_alice)
AI: こんにちは、アリスさん！どうぞよろしくお願いします。何かお手伝いできることはありますか？

[アリス] 2回目の入力:
  (既存セッション再開: user_alice)
AI: はい、アリスさん、覚えていますよ！何かありましたか？

--- セッション 'user_bob' での対話開始 ---

[ボブ] 1回目の入力:
  (新規セッション開始: user_bob)
AI: 日本の首都は東京です。

--- セッション 'user_alice' に戻って対話 ---

[アリス] 3回目の入力:
  (既存セッション再開: user_alice)
AI: かしこまりました！一つジョークを言いますね。
パンはパンでも食べられないパンはなーんだ？
…答えはフライパン！ 😄

--- 最終的な履歴ストアの中身 ---
セッションID: user_alice
  - HumanMessage: こんにちは、私の名前はアリスです。
  - AIMessage: こんにちは、アリスさん！どうぞよろしくお願いします。何かお手伝いできることはありますか？
  - HumanMessage: 私の名前、覚えていますか？
  - AIMessage: はい、アリスさん、覚えていますよ！何かありましたか？
  - HumanMessage: 面白いジョークを一つ教えてください。
  - AIMessage: かしこまりました！一つジョークを言いますね。\nパンはパンでも食べられないパンはなーんだ？\n…答えはフライパン！ 😄
セッションID: user_bob
  - HumanMessage: 日本の首都はどこですか？
  - AIMessage: 日本の首都は東京です。

--- 処理終了 ---
```

- この実行結果から、AI がアリスの名前を記憶し、ボブの質問には独立して答え、最後に各セッションの履歴が正しく保存されていることが確認できます。メモリ機能が期待通りに動作していますね！

---

## 4. 深掘り解説：仕組みをもっと詳しく知ろう

### 🎯 目標

- `RunnableWithMessageHistory` が内部でどのように動作しているのか、その流れをより深く理解し、特に `get_session_history` 関数の役割とカスタマイズの可能性について知識を深めます。

### `RunnableWithMessageHistory` の実行フロー（もう少し詳しく）

`chain_with_memory.invoke(...)` が呼ばれたときの内部的なステップは以下のようになります。

1.  **セッション特定:** `config={"configurable": {"session_id": "..."}}` からセッション ID を取り出します。
2.  **履歴ロード:** あなたが定義した `get_session_history(セッションID)` を呼び出し、このセッションに対応する履歴オブジェクトを取得します。
3.  **プロンプト構築:** 取得した履歴をプロンプトテンプレートの `MessagesPlaceholder` に挿入し、今回のユーザー入力も組み込みます。
4.  **コア処理実行:** 元々のチェーン（`prompt | llm | parser`）を実行します。
5.  **履歴セーブ:** 今回のユーザー入力と AI 応答を、ステップ 2 で取得した履歴オブジェクトに保存します。
6.  **結果返却:** AI の応答を最終結果として返します。

このように、履歴の読み書きという定型的な処理を自動化してくれるのが、この仕組みの便利な点です。

### `get_session_history` の重要性：履歴管理の心臓部

この関数こそが、会話履歴の管理方法を決定づける部分です。

- **スコープ決定:** この関数内で `session_id` をどう扱うかで、履歴がどの範囲（ユーザーごと、一時的なセッションごとなど）で有効になるかが決まります。
- **永続化への扉:** 履歴を永続化したい場合、**この関数の中身を変更するだけ**で対応できます。例えば、Redis に保存したいなら `RedisChatMessageHistory` を、ファイルなら `FileChatMessageHistory` を返すように書き換えることで、他のコードを変更せずに保存方法を切り替えられます。
- **型ヒントと柔軟性:** 関数の返り値の型ヒントを `BaseChatMessageHistory` としたのは、LangChain が `ChatMessageHistory` だけでなく、`FileChatMessageHistory` や `RedisChatMessageHistory` など、`BaseChatMessageHistory` という共通のルールに従うクラスならどれでも扱えることを示すためです。これにより高い柔軟性が保たれます。

### 履歴の長さに注意（コンテキストウィンドウ）

`RunnableWithMessageHistory` は自動で履歴を追加していきますが、多くの LLM には一度に処理できるテキスト量（コンテキストウィンドウ）に上限があります。会話が非常に長くなると、すべての履歴をプロンプトに入れると上限を超えてしまい、エラーになる可能性があります。

実際のアプリケーションでは、履歴が長くなりすぎないように、古いメッセージを削除したり、要約したりする工夫が必要になることがあります。これは応用的なトピックですが、履歴は無限に保持できるわけではない、という点は覚えておきましょう。

---

## 5. 最終チェック：動作確認と問題解決

### 🎯 目標

- 作成したメモリ付きチェーンが、セッション ID に基づいて正しく会話履歴を管理し、文脈に沿った応答を生成できているかを最終確認します。

### 確認してみよう！

- **実行:** `step10_lcel_with_memory.py` を実行し、エラーなく完了するか確認してください。
- **アリスの会話:**
  - 2 回目の応答で、AI はちゃんと「アリスさん」と呼びかけましたか？
  - 3 回目の応答で、AI は「面白いジョーク」という新しい質問に適切に答えましたか？
- **ボブの会話:**
  - ボブの 1 回目の応答は、アリスの会話の影響を受けずに、「日本の首都」について正しく答えましたか？
- **履歴ストア:** 最後の出力で、`user_alice` と `user_bob` の両方のセッション ID が表示され、それぞれの会話履歴が正しく格納されていることを確認してください。

これらの点が期待通りであれば、LCEL チェーンにメモリを組み込む基本をマスターしました！

---

## 6. まとめ：学びの整理と次へのステップ

### 🎯 目標

- `RunnableWithMessageHistory` を使った LCEL チェーンへのメモリ組み込み方法を確実に理解し、その知識を定着させます。

### ✅ 達成したこと！

- LCEL チェーンに会話履歴（メモリ）を自動的に統合する `RunnableWithMessageHistory` の使い方を学びました（または、それに相当する `.with_message_history()` メソッドの考え方を理解しました）。
- `get_session_history` 関数を自分で定義し、セッション ID に基づいて会話ごとに履歴を管理する方法を実装できました。
- プロンプトテンプレート内で `MessagesPlaceholder` を使って履歴を動的に挿入する方法を理解しました。
- これにより、過去の会話文脈を踏まえて応答することができる、より高度な LCEL チェーンを構築できるようになりました。

### 🔑 学んだキーワード

- **`RunnableWithMessageHistory`** (from `langchain_core.runnables.history`)
- **`.with_message_history()`** (Runnable のメソッド、内部で上記を使用)
- **`get_session_history`** (履歴取得・管理のための自作関数)
- **セッション ID (`session_id`)** (会話の識別子)
- `input_messages_key`, `history_messages_key` (設定用キー)
- **`MessagesPlaceholder`** (from `langchain_core.prompts`, 履歴挿入用)
- `config={"configurable": {"session_id": ...}}` (実行時設定)
- メモリ付きチェーン (Chain with Memory)
- `BaseChatMessageHistory` (履歴クラスの共通インターフェース)
- (注意点) コンテキストウィンドウ、インメモリ vs 永続化

### 🚀 次のステップへ！

これで AI が会話を覚えてくれるようになり、チャットボット開発の可能性が大きく広がりましたね！ このメモリ機能は、ストリーミング応答 (`.stream()`) や非同期実行 (`.ainvoke()`) でも利用できるため、さらに応用が可能です。

さて、次は AI にもっと**個性**を持たせてみましょう。次の **ステップ 11「ボットに性格を！役割と会話を調整」** では、プロンプトエンジニアリングのテクニック、特に `SystemMessage` を活用して、AI に特定の役割（例：「古代の賢者」「未来からのロボット」）を演じさせたり、話し方や性格を調整したりする方法を学びます。今回作ったメモリ付きチェーンをベースに、より魅力的で一貫性のあるキャラクターを持つ AI を作り上げていきましょう！
