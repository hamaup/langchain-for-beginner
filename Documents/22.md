前のステップでは、RAG チェーンの出力に回答の根拠となる **出典情報** を含める方法を実装し、システムの透明性を高めました。

今回は、RAG システムの回答品質に直接影響する **LLM への指示（プロンプト）** の最適化に焦点を当てます。ステップ 17 で作成した基本的な RAG プロンプトは、LLM が Context を無視したり、Context に情報がない場合に不確かな情報を生成（**ハルシネーション**）したりする可能性がありました。

このステップでは、これらの問題を軽減し、LLM が提供された **Context** を最大限に活用して、より**忠実**で**信頼できる**回答を生成するように導くための、**RAG プロンプト最適化**のテクニックを解説します。

## 1. はじめに：このステップで目指すこと

### 🎯 今回のゴール

このステップを完了すると、以下のことができるようになります。

- RAG におけるプロンプトの重要性と、最適化によって改善できる点を理解します。
- LLM に対して、提供された **Context** に**基づいてのみ**回答するように指示する（**Context Grounding**）ためのプロンプトの記述方法を学びます。
- Context に回答が含まれていない場合に、LLM が**知らないと応答する**ように促す方法を習得します。
- **具体的な成果物:** ステップ 21 で作成した RAG チェーンのプロンプト部分を改良し、より Context に忠実で、情報がない場合には指定された応答（例: 「分かりません」）を返す RAG チェーンの Python コードを作成し、その効果を確認します。

### 🔑 このステップのポイント

このステップで特に重要な考え方や技術です。

- **RAG プロンプト最適化:** RAG システムの回答品質を高めるためのプロンプト調整。
- **プロンプトエンジニアリング:** LLM から望ましい出力を得るための指示設計技術。
- **Context Grounding (コンテキスト接地):** 回答の根拠を、提供された Context に限定すること。
- **ハルシネーション抑制:** LLM が事実に基づかない情報を生成するのを防ぐこと。
- **未知の質問への対応:** Context に答えがない場合の適切な応答方法の指示。
- **構造化プロンプト:** タグなどを用いて情報を整理し、LLM の理解を助ける手法。

### ✅ 前提知識

このステップに進む前に、以下の準備と知識を確認してください。

- **ステップ 21「回答の根拠は？引用情報を表示」の内容:** 回答と Context の両方を出力する RAG チェーンを LCEL で構築できること。**`itemgetter`** を使用したデータフローを理解していること。
- **LCEL の基本:** チェーンの構造と **`ChatPromptTemplate`** の基本的な使い方。
- **Python の基本:** 文字列操作、関数の定義、辞書・リスト操作。
- 必要なライブラリと API キーが設定されていること。(FAISS を使う前提で進めます)

準備ができていれば、プロンプト最適化の実装に進みましょう。

---

## 2. 準備運動：なぜ RAG プロンプトは特別なのか？

### 🎯 目標

通常の LLM プロンプトと RAG プロンプトの違い、そして RAG 特有のプロンプト設計が必要となる理由を理解します。

### 通常のプロンプトと RAG プロンプト

通常の LLM への質問では、モデルが持つ広範な学習データに基づいて回答が生成されます。一方、RAG では、提供された特定の **Context** を主要な情報源として利用するように LLM に指示する必要があります。これは、LLM の内部知識ではなく、外部から与えられた最新または特定の情報に基づいて回答を得たいという RAG の目的に起因します。

### RAG プロンプトにおける課題

基本的な RAG プロンプト（Context と Question を並べるだけ）では、LLM が Context を十分に参照しなかったり、Context に情報がない場合に自身の知識で補完しようとして不正確な情報を生成（**ハルシネーション**）したりする可能性があります。

これを防ぐためには、プロンプト内で LLM の動作をより明確に指示する必要があります。

**主な指示のポイント:**

1.  **Context 利用の強制:** 提供された Context の情報のみに基づいて回答するように明確に指示する。
2.  **未知情報への対応:** Context に回答がない場合の応答方法（例: 「分かりません」と回答する）を具体的に指示する。
3.  **情報の構造化:** Context と Question の区別を明確にする。

これらの指示をプロンプトに組み込むことで、LLM は RAG の意図をより正確に理解し、Context に忠実な回答を生成する可能性が高まります。

---

## 3. 実践タイム：RAG プロンプトを改良する

### 🎯 目標

LCEL チェーン内の **`ChatPromptTemplate`** を、Context Grounding と未知の質問への対応指示を含むように改良し、その効果を確認します。

### ステップ・バイ・ステップ実装

#### 1. 準備 (ステップ 21 のコードをベースに):

ステップ 21 で作成したコード (`step21_rag_citation_final.py`) をベースとします。インポート文、LLM、Retriever、Context フォーマット関数などは基本的に流用します。

```python
# step22_rag_prompt_optimization_formal.py
import os
import sys
from dotenv import load_dotenv
from operator import itemgetter # ステップ21の修正で使用

# --- 必要な LangChain モジュール ---
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_core.prompts import ChatPromptTemplate # ← これを改良
from langchain_core.output_parsers import StrOutputParser
from langchain_core.documents import Document
from langchain_core.runnables import RunnablePassthrough, RunnableLambda, RunnableParallel

# Vector Store (FAISS)
try:
    from langchain_community.vectorstores import FAISS
    import faiss
    print("FAISS をインポートしました。")
except ImportError:
    print("エラー: FAISS または langchain-community が見つかりません。\n   'pip install faiss-cpu langchain-community' を実行してください。")
    sys.exit(1)

# Text Splitter (サンプル文書用)
try:
    from langchain_text_splitters import RecursiveCharacterTextSplitter
    print("RecursiveCharacterTextSplitter をインポートしました。")
except ImportError:
    print("エラー: RecursiveCharacterTextSplitter が見つかりません。\n   'pip install langchain-text-splitters' を実行してください。")
    sys.exit(1)

# トークン計算用
try:
    import tiktoken
    print("tiktoken をインポートしました。")
except ImportError:
    print("エラー: tiktoken が見つかりません。\n   'pip install tiktoken' を実行してください。")
    sys.exit(1)

print("--- 必要なモジュールのインポート完了 ---")

# --- 基本設定 (LLM, Embedding) ---
load_dotenv()
openai_api_key = os.getenv("OPENAI_API_KEY")
if not openai_api_key:
    print("エラー: OpenAI API キーが設定されていません。")
    sys.exit(1)
else:
    print("OpenAI API キーを読み込みました。")

try:
    embedding_dim = 1536
    embeddings_model = OpenAIEmbeddings(model="text-embedding-3-small", api_key=openai_api_key)
    llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0, api_key=openai_api_key)
    print(f"--- Embedding モデルと LLM 準備完了 ---")
except Exception as e:
    print(f"エラー: モデルの初期化に失敗しました: {e}")
    sys.exit(1)

# --- Vector Store と Retriever の準備 ---
sample_documents = [
    Document(page_content="LangChain は LLM アプリケーション開発を支援するフレームワークです。", metadata={"source": "doc-b", "page": 1}),
    Document(page_content="LCEL は LangChain Expression Language の略で、チェーン構築を容易にします。", metadata={"source": "doc-b", "page": 2}),
    Document(page_content="エージェントはツールを使って外部システムと対話し、タスクを実行します。", metadata={"source": "doc-c", "page": 1}),
    Document(page_content="LangGraph は状態を持つ複雑なグラフを構築できます。", metadata={"source": "doc-a", "page": 1}),
]
try:
    vector_store = FAISS.from_documents(sample_documents, embeddings_model)
    retriever = vector_store.as_retriever(search_kwargs={'k': 2})
    print("--- Vector Store (FAISS) と Retriever 準備完了 (k=2) ---")
except Exception as e:
    print(f"エラー: Vector Store または Retriever の準備中にエラー: {e}")
    sys.exit(1)

# --- Context フォーマット関数 ---
def format_docs(docs: list[Document]) -> str:
    return "\n\n".join(doc.page_content for doc in docs)
format_docs_runnable = RunnableLambda(format_docs)
print("--- Context フォーマット関数準備完了 ---")

```

#### 2. ★ 改良版 RAG プロンプトテンプレートの作成 ★:

新しいプロンプトテンプレートを作成し、「Context に基づく回答」と「未知の質問への対応」に関する指示を追加します。

```python
# step22_rag_prompt_optimization_formal.py (続き)

print("\n--- ★ 改良版 RAG プロンプトテンプレートの作成 ★ ---")

# 改良版プロンプトテンプレート
new_template = """
以下の指示に従って、与えられた Context の情報のみを使用して質問に回答してください。
- 回答は Context の内容に厳密に基づいて生成してください。
- Context に質問に対する回答が明確に含まれていない場合は、追加情報を提供しようとせず、「提供された情報の中には、ご質問に該当する内容が見つかりませんでした。」と正確に回答してください。
- Context 以外の知識や外部の情報を使用しないでください。

<context>
{context}
</context>

<question>
{question}
</question>

回答:"""

# 新しいテンプレートから ChatPromptTemplate を作成
new_rag_prompt = ChatPromptTemplate.from_template(new_template)

print("--- 改良版 RAG プロンプトテンプレート準備完了 ---")
print("--- 新しい指示内容 ---")
print(new_rag_prompt.template)
```

- 指示をより明確にし、箇条書きにしました。
- 未知の場合の応答も具体的に指定しました。
- 構造化タグと末尾の「回答:」は維持しました。

#### 3. 改良版プロンプトを使った RAG チェーンの組み立て:

ステップ 21 のチェーン構造をベースに、プロンプト部分を今作成した `new_rag_prompt` に差し替えます。

```python
# step22_rag_prompt_optimization_formal.py (続き)

print("\n--- 改良版プロンプトを使った RAG チェーンの組み立て ---")

# 1. Context 取得と質問保持 (ステップ 21 と同じ)
setup_and_retrieval = RunnableParallel(
    context=itemgetter("question") | retriever,
    question=itemgetter("question")
)

# 2. 回答生成チェーン (★プロンプトを new_rag_prompt に変更★)
new_answer_generation_chain = (
    new_rag_prompt # ← 差し替え
    | llm
    | StrOutputParser()
)

# 3. 全体の組み立て (★回答生成部分を new_answer_generation_chain に変更★)
new_rag_chain_with_source = (
    setup_and_retrieval
    | RunnableParallel(
          answer=RunnablePassthrough.assign(
              context=itemgetter("context") | format_docs_runnable
          ) | new_answer_generation_chain, # ← 差し替え
          context=itemgetter("context")
      )
)

print("--- 改良版 RAG チェーン組み立て完了 ---")
```

#### 4. 改良版 RAG チェーンの実行と比較:

新しいチェーンを使って、Context に答えがある質問と、答えがない質問の両方を実行し、応答の違いを確認します。

```python
# step22_rag_prompt_optimization_formal.py (続き)

# --- 出典表示用関数 ---
def print_sources(context_docs):
    if context_docs:
        print(f"({len(context_docs)} 件の Context が参照されました)")
        for doc in context_docs:
            source = doc.metadata.get("source", "不明")
            page = doc.metadata.get("page", "-")
            print(f"- 出典: {source}, ページ: {page}")
    else:
        print("出典情報が見つかりませんでした。")

# --- 改良版 RAG チェーンの実行 ---

# --- ケース 1: Context に答えがある質問 ---
question_1 = "LCEL は何の略称ですか？"
print(f"\n--- 実行ケース 1 (質問: '{question_1}') ---")
try:
    output_1 = new_rag_chain_with_source.invoke({"question": question_1})
    print("\n[AIの回答 1]")
    print(output_1.get("answer", "回答なし"))
    print("\n[出典情報 1]")
    print_sources(output_1.get("context"))

except Exception as e: print(f"エラー1: {e}")

# --- ケース 2: Context に答えがない質問 ---
question_2 = "Python の async/await について詳しく教えて" # サンプル文書にはない内容
print(f"\n--- 実行ケース 2 (質問: '{question_2}') ---")
try:
    output_2 = new_rag_chain_with_source.invoke({"question": question_2})
    print("\n[AIの回答 2]")
    print(output_2.get("answer", "回答なし")) # ← 指示通りの応答を期待
    print("\n[出典情報 2]")
    print_sources(output_2.get("context")) # Context自体は取得される場合がある

except Exception as e: print(f"エラー2: {e}")


print("\n--- 処理終了 ---")

```

- 出典表示のロジックを `print_sources` 関数にまとめ、コードを整理しました。
- ケース 2 で、プロンプトで指示した通りの応答（「提供された情報の中には～」）が返ってくるかを確認します。

### 完成コード (`step22_rag_prompt_optimization_formal.py`)

上記の実装 1〜4 を結合したものが、このステップの完成コードです。

### 実行結果の例

```text
# ...(初期化ログ)...
--- Vector Store (FAISS) と Retriever 準備完了 (k=2) ---
--- Context フォーマット関数準備完了 ---

--- ★ 改良版 RAG プロンプトテンプレートの作成 ★ ---
--- 改良版 RAG プロンプトテンプレート準備完了 ---
--- 新しい指示内容 ---
# (new_template の内容が表示される)

--- 改良版プロンプトを使った RAG チェーンの組み立て ---
--- 改良版 RAG チェーン組み立て完了 ---

--- 実行ケース 1 (質問: 'LCEL は何の略称ですか？') ---

[AIの回答 1]
LCEL は LangChain Expression Language の略です。

[出典情報 1]
(1 件の Context が参照されました)
- 出典: doc-b, ページ: 2

--- 実行ケース 2 (質問: 'Python の async/await について詳しく教えて') ---

[AIの回答 2]
提供された情報の中には、ご質問に該当する内容が見つかりませんでした。

[出典情報 2]
(2 件の Context が参照されました) # Retriever は何か関連しそうなものを返すが...
- 出典: doc-b, ページ: 2       # ...LLM は使えないと判断
- 出典: doc-b, ページ: 1

--- 処理終了 ---
```

- ケース 1 では Context に基づいた回答、ケース 2 ではプロンプトで指示した通りの応答が得られ、プロンプトの最適化が効果を発揮していることが確認できます。

---

## 4. 深掘り解説：効果的な RAG プロンプトとは？

### 🎯 目標

RAG におけるプロンプトエンジニアリングの重要性と、今回試したテクニック、さらに他の有効な工夫や注意点について理解を深めます。

### RAG プロンプトエンジニアリングの重要性

RAG システムの性能は、Retriever が持ってくる Context の質だけでなく、その Context を LLM が**どのように利用するか**にも大きく依存します。プロンプトは、LLM にその利用方法を指示する設計図であり、回答の**忠実度**、**ハルシネーション**の抑制、そして**回答スタイル**を左右する重要な要素です。

### 今回使ったテクニック

- **Context Grounding (接地) の強化:** 「Context の情報**のみ**を使用して」「Context 以外の知識を使用しないでください」といった指示により、LLM が内部知識に頼ることを抑制します。
- **未知の質問への対応指示:** 「Context に回答が明確に含まれていない場合は、『提供された情報の中には～』と正確に回答してください」のように具体的な応答を指定することで、LLM は情報がない場合に不確かな応答を生成するのではなく、定義された応答を返すようになります。
- **構造化タグ (`<context>`, `<question>`):** LLM がプロンプトの各部分の役割を明確に区別するのを助けます。

### 他の有効なテクニック例

- **役割の付与 (Role Playing):** 「あなたは、提供された文書に基づいて質問に答えるアシスタントです」のように役割を与える。
- **思考ステップの指示 (Chain-of-Thought):** 複雑な質問に対し、段階的な思考プロセス（例: 関連箇所抽出 → 要約 → 回答）を指示する（応用）。
- **Few-Shot プロンプティング:** 特定の回答形式を強く要求したい場合に、質問と模範解答のペアを例として示す。

### プロンプトは継続的に改善するもの

最適なプロンプトは、対象データ、タスク、使用する LLM モデルによって異なります。万能なプロンプトは存在しないため、様々な質問で応答を評価し、**繰り返し改善していくプロセス**が不可欠です。

### 注意点：Context Window と LLM の特性

- **Context Window:** プロンプト全体のトークン数（指示＋ Context ＋質問）が LLM の上限を超えないように注意が必要です。Retriever の `k` の値や Context 圧縮 (ステップ 19) で調整します。
- **LLM の特性:** プロンプトの指示に対する従属性（Instruction Following 能力）は LLM によって異なります。あるモデルで効果的なプロンプトが、別のモデルではうまく機能しないこともあります。
- **Tokenizer:** `tiktoken` は OpenAI モデルに特化しています。他の LLM を使用する場合は、適切なトークナイザを検討する必要があります。

---

## 5. 最終チェック：指示通りに動いてくれた？

### 🎯 目標

改良したプロンプトを使った RAG チェーンが、意図した通りに Context に基づいた回答を生成し、情報がない場合には指示通りの応答をするかを確認します。

### 確認してみましょう！

- **実行:** `step22_rag_prompt_optimization_formal.py` を実行してください。
- **エラーなし？:** エラーなく最後まで実行できましたか？
- **ケース 1 (答えがある場合):** AI の回答は Context の内容を正しく反映していましたか？ Context 外の情報で補足されていませんでしたか？
- **ケース 2 (答えがない場合):** AI の回答は、プロンプトで指示した通りの応答（「提供された情報の中には～」）になっていましたか？ 不確かな情報を生成していませんか？
- **(実験) 指示変更:** `new_template` の指示内容を変更して実行すると、AI の応答が変わるか試してみましょう。

これらが期待通りであれば、プロンプト最適化による RAG 改善の基本は習得できています。

---

## 6. まとめ：学びの整理と次へのステップ

### ✅ 達成したこと！

これで、RAG システムの回答品質を向上させるための重要なスキル、プロンプトの最適化をマスターしました！

- RAG における**プロンプトエンジニアリング**の重要性を理解しました。
- LLM に **Context** に基づいて回答させ、**ハルシネーション**を抑制するための具体的な指示方法を学びました。
- Context に答えがない場合に、LLM に**指定した応答**をさせるプロンプトを作成・実装しました。
- **構造化タグ**などを利用して、LLM がプロンプトを理解しやすくする工夫を知りました。
- プロンプトの調整が、RAG システム全体の**信頼性**と**品質**に大きく影響することを実感しました。

### 🔑 学んだキーワード

- **RAG プロンプト最適化 (RAG Prompt Optimization)**
- **プロンプトエンジニアリング (Prompt Engineering)**
- **Context Grounding (コンテキスト接地)**
- **ハルシネーション抑制 (Hallucination Reduction)**
- **未知の質問への対応**
- **構造化タグ (例: `<context>`)**
- **ChatPromptTemplate**

### 🚀 次のステップへ！

RAG チェーンの構築から、検索改善、出典表示、そしてプロンプト最適化まで、RAG システムの主要な要素を一通り学びました。これで、かなり高度な RAG アプリケーションの基礎ができたと言えるでしょう。

しかし、作ったシステムが「本当に良いものか？」を客観的に知るためには、**評価**というステップが欠かせません。

次の **ステップ 23「アプリの評価とデバッグ入門」** では、作成した RAG アプリケーションの性能をどのように評価するのか、その基本的な考え方や指標（例: 回答の忠実度、関連性など）について学びます。また、もしシステムが期待通りに動作しない場合に、どこに問題があるのかを突き止めるための**デバッグ**の初歩的なアプローチにも触れていきます。作成したシステムを客観的に評価し、改善していくための重要なステップに進みましょう。
